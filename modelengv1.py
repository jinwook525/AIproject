import torch
import torch.nn as nn
import logging
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        return self.fc(lstm_out[:, -1, :])  # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ì¶œë ¥ ì‚¬ìš©

# âœ… ì €ì¥ëœ ëª¨ë¸ê³¼ ë™ì¼í•œ ì„¤ì • ì‚¬ìš©
INPUT_SIZE = 30  # ğŸš¨ ì €ì¥í•  ë•Œ ì‚¬ìš©í•œ X_train.shape[2] ê°’ê³¼ ë™ì¼í•´ì•¼ í•¨
HIDDEN_SIZE = 128  # ğŸš¨ ì €ì¥í•  ë•Œ ì‚¬ìš©í•œ hidden_size ê°’ê³¼ ë™ì¼í•´ì•¼ í•¨
NUM_LAYERS = 2  # ë™ì¼í•´ì•¼ í•¨
OUTPUT_SIZE = 2  # ë™ì¼í•´ì•¼ í•¨
DROPOUT = 0.0  # ë™ì¼í•´ì•¼ í•¨

# âœ… ëª¨ë¸ ì´ˆê¸°í™” í›„ ê°€ì¤‘ì¹˜ ë¡œë“œ
model = LSTMModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE, DROPOUT)

try:
    state_dict = torch.load("lstm_model_v1.pth", map_location=torch.device("cpu"))  # âœ… ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ
    model.load_state_dict(state_dict)  # âœ… ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë¸ì— ì ìš©
    model.eval()  # âœ… í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    print("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤!")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit(1)

def predict(input_data):
    """ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ì•„ LSTM ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰"""
    if not isinstance(input_data, torch.Tensor):
        input_data = torch.tensor(input_data, dtype=torch.float32)  # NumPy ë°°ì—´ì„ Tensorë¡œ ë³€í™˜
    
    logging.info(f"ğŸ“Œ ì›ë³¸ ì…ë ¥ ë°ì´í„° shape: {input_data.shape}")  # âœ… ë³€í™˜ ì „ shape í™•ì¸

    # âœ… ì°¨ì› ë³€í™˜ (LSTMì´ ìš”êµ¬í•˜ëŠ” 3D ì…ë ¥ í˜•íƒœë¡œ ë³€ê²½)
    if input_data.dim() == 1:
        input_data = input_data.unsqueeze(0).unsqueeze(0)  # (1, 1, input_size)
    elif input_data.dim() == 2:
        input_data = input_data.unsqueeze(0)  # (1, sequence_length, input_size)

    logging.info(f"ğŸ“Œ ë³€í™˜ í›„ ì…ë ¥ ë°ì´í„° shape: {input_data.shape}")  # âœ… ë³€í™˜ í›„ shape í™•ì¸

    with torch.no_grad():
        output = model(input_data)
    
    return output.squeeze().tolist()  # ì˜ˆì¸¡ê°’ ë°˜í™˜

